---
title: "Elements de probabilités"
format: revealjs
editor: visual
---

# Notions de bases

## Expérience aléatoire

Une **expérience aléatoire** est une expérience :

-   qui peut être répétée
-   qui a plusieurs résultats possibles
-   dont le résultat est imprévisible

Exemples :

-   lancé d'un dé à 6 faces
-   observation du statut maladie d'une plantes

## Évènement élémentaire

Un **évènement élémentaire** est le **résultat d'une expérience aléatoire**.

Exemples :

-   Obtenir 6 lors du lancé d'un dé à 6 faces
-   Observé une plante malade

## Ensemble fondamental / Univers

**L'ensemble fondamental ou l'univers** est l'ensemble de tous les résultats possibles (évènements élémentaires) d'une expérience aléatoire.

Il est noté $\Omega$ (ou S).

$\Omega$ peut être :

-   un ensemble fini ($\Omega$ discret)
-   un ensemble infini dénombrable ($\Omega$ discret)
-   un ensemble infini indénombrable ($\Omega$ continu)

## Évènement (non élémentaire)

Un événement (non élémentaire) est un sous-ensemble de $\Omega$

Exemple :

**Si** l'évènement A est « Obtenir un résultat strictement supérieur à 4 lors du lancé d'un dé à 6 faces »,

**alors** A = $\{5,6\}$

**Évènements particuliers** :

-   L'évènement **total** $\Omega$ est certain
-   L'ensemble **vide** $\varnothing$ est un évènement impossible

## Opérations sur les évènements

:::::: columns
::: {.column width="46%"}
### Union

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-07.jpg?height=324&width=455&top_left_y=151&top_left_x=81)

L'événement $A \cup B$ est réalisé dès que $A$ ou $B$ est réalisé.
:::

::: {.column width="4%"}
:::

::: {.column width="50%"}
### Intersection

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-07.jpg?height=327&width=451&top_left_y=578&top_left_x=85)

L'événement $A \cap B$ est réalisé dès que $A$ et $B$ sont réalisés dans la même expérience.
:::
::::::

## 

### Complémentaire de A

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-08.jpg?height=253&width=503&top_left_y=270&top_left_x=81){width="50%"}

L'événement **complémentaire** de $A$, noté $\bar{A}$ contient tous les éléments de $\Omega$ qui ne sont pas dans $A$.

En particulier

-   $\overline{A \cap B}=\bar{A} \cup \bar{B}$
-   $\overline{A \cup B}=\bar{A} \cap \bar{B}$

## 

### Évènements incompatibles

A et B sont dits incompatibles si $A \cap B=\varnothing$

### Système complet d'évènements

::::: columns
::: {.column width="50%"}
Toute partition de $\Omega$, c'est à dire tout ensemble d'évènement $\left(A_{i}\right)$ tel que

-   $A_{i} \neq \varnothing$
-   $\forall i \neq j, A_{i} \cap A_{j}=\varnothing$
-   $\bigcup_{i} A_{i}=\Omega$
:::

::: {.column width="50%"}
![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-09.jpg?height=285&width=421&top_left_y=638&top_left_x=716)
:::
:::::

# Probabilité

## Probabilité

On appelle probabilité

$$P : \Omega \to [0,1]$$ tel que

-   $P(\Omega)=1$
-   **Si** A et B sont incompatibles, **alors** $$P(A \cup B)=P(A)+P(B)$$

## 

### Propriétés

-   $P(\Omega)=1 \quad \text { (définition) }$
-   $P(\varnothing)=0$
-   $P(A) \leq 1$
-   $P(\bar{A})=1-P(A)$
-   Pour 2 évènements $A$ et $B$, $$P(A \cup B)=P(A)+P(B)-P(A \cap B)$$

## 

### Probabilité sur un ensemble $\Omega$ fini

$$\Omega=\left\{\omega_{1} ; \omega_{2} ; \ldots ; \omega_{n}\right\}$$ Pour définir une probabilité sur $\Omega$ il suffit de se donner $n$ nombres réels $p_{i}$ tels que

$$\forall i, p_{i} \geq 0 \quad \mbox{et} \quad \sum_{i=1}^{n} p_{i}=1$$

Les $p_{i}$ sont les probabilités des évènements élémentaires $\left\{\omega_{i}\right\}$

## 

La probabilité d'un évènement A quelconque est la somme des probabilités des évènements élémentaires qui constituent A.

### Cas particulier de l'équiprobabilité

Tous les évènements élémentaires ont la **même probabilité**.

Les probabilités des évènements élémentaires $\omega_i$ sont $p_{1}=p_{2}=\ldots=p_{n}=\dfrac{1}{n}$

$$
P(A)=\frac{\text { nombre de cas favorables à la réalisation de } A}{\text { nombre de cas possibles de l'ensemble } \Omega}
$$

$\to$ problèmes de dénombrement

# Probabilité conditionnelle

## Probabilité conditionnelle

Soit $B$ un évènement de probabilité **non nulle**

Pour tout évènement $A$, on appelle **probabilité conditionnelle de A** sachant que B est réalisé

$$
P(A \mid B)=\frac{P(A \cap B)}{P(B)}
$$

$P(A|B)$ vérifie toutes les propriétés des probabilités, en particulier

## 

### Formules des probabilités composées

De la définition des probabilités conditionnelles, on déduit

$$
P(A \cap B)=P(B) \times P(A \mid B)
$$

De même $$P(B \cap A)=P(A) \times P(B \mid A)$$ Or, $P(A \cap B)=P(B \cap A)$ Donc $$P(A \cap B)= P(A \mid B) \times P(B) = P(B \mid A) \times P(A)$$

$\to$ Généralisation possible pour $n$ évènements

## 

### Formule des probabilités totales

On considère une partition de $\Omega$ en 2.

$A$ et $\bar{A}$ forment un système complet d'évènements.

Pour tout évènement $B$ :

$$P(B)=P(B \mid A) \times P(A)+P(B \mid \bar{A}) \times P(\bar{A})$$

$\to$ Généralisation possible pour $n$ évènements

## 

### Démonstration

::::: columns
::: {.column width="60%"}
-   $B=B \cap \Omega=B \cap(A \cup \bar{A})$
-   $B=(B \cap A) \cup(B \cap \bar{A})$
-   $B \cap A$ et $B \cap \bar{A}$ sont incompatibles donc $P(B)=P(B \cap A)+P(B \cap \bar{A})$
:::

::: {.column width="40%"}
![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-22.jpg?height=245&width=475&top_left_y=464&top_left_x=720)
:::
:::::

Donc on applique la formule des probabilités composées et on obtient $$P(B)=P(B \mid A) \times P(A)+P(B \mid \bar{A}) \times P(\bar{A})$$

## Le théorème de Bayes

### Énoncé du théorème dans le cas général

Soient $\left\{A_{1} ; A_{2} ; \ldots ; A_{n}\right\}$ un système complet d'évènements et $B$ un évènement de probabilité non nulle.

Pour tout $j$ on a :

$$P\left(A_{j} \mid B\right)=\frac{P\left(A_{j}\right) \times P\left(B \mid A_{j}\right)}{P(B)}$$ donc $$P\left(A_{j} \mid B\right) = \frac{P\left(A_{j}\right) \times P\left(B \mid A_{j}\right)}{\sum_{i=1}^{n} P\left(A_{i}\right) \times P\left(B \mid A_{i}\right)}$$

## 

### Exemple d'application :

Etude d'une maladie sur des pieds de tomates sur une exploitation maraichere.

On connait :

-   la probabilité de cette maladie $P(M)$
-   la probabilité qu'un test diagnostique soit positif pour des pieds de tomates malades $P\left(T^{+} \mid M\right)$
-   la probabilité qu'un test diagnostique soit positif pour des pieds de tomates sains $P\left(T^{+} \mid \bar{M}\right)$

**Objectif** : Calculer $P\left(M \mid T^{+}\right)$

# Indépendance

## Indépendance de 2 évènements

Deux évènements $A$ et $B$ de probabilité non nulle sont **indépendants** (relativement à la probabilité P) ssi $$P(A \mid B)=P(A)$$

De la même façon $$P(B \mid A)=P(B)$$

Ou autrement dit $A$ et $B$ sont indépendants (relativement à la probabilité P) ssi $$P(A \cap B)=P(A) \times P(B)$$

## 

### Théorème

Les affirmations suivantes sont équivalentes

-   $A$ et $B$ sont **indépendants**
-   $A$ et $\bar{B}$ sont **indépendants**
-   $\bar{A}$ et $B$ sont **indépendants**
-   $\bar{A}$ et $\bar{B}$ sont **indépendants**

## Indépendance et incompatibilité

Deux notions différentes !

-   $A$ et $B$ incompatibles : $A \cap B=\varnothing$

Ne fait pas intervenir la probabilité

-   $A$ et $B$ indépendants : $P(A \cap B)=P(A) \times P(B)$

## 

**Question** :

Deux évènements de probabilité non nulle incompatibles sont-ils indépendants ?

-   On a $A$ et $B$ incompatibles : $A \cap B=\varnothing$, donc $P(A \cap B)=0$
-   Or, $P(A) \neq 0$ et $P(B) \neq 0$, donc $P(A) \times P(B) \neq 0$
-   Donc $P(A \cap B) \neq P(A) \times P(B)$

**Conclusion** :

$A$ et $B$ ne sont pas indépendants

**Deux évènements de probabilité non nulle incompatibles ne sont donc pas indépendants.**

## Épreuves / Expériences indépendantes

On parle d'**épreuves indépendantes** lorsque le résultat d'une des épreuves n'a aucune influence sur les résultats des autres épreuves.

### Propriété

Lors d'une répétition de n épreuves indépendantes, la probabilités d'une issue est égale au poduit des probabilité de chacunes des issues du n épreuves indépendantes

## 

### Application en statistique

Constitution de n-échantillons (cf chapitre suivant "Estimation et intervalle de confiance")

**Exemple :**

Réalisation de 5 lancés d'une pièce équilibrée.

$F_{i}$ : «Obtenir face au i-ème lancé »

La probabilité $p$ d'obtenir 5 fois face :

$$P\left(F_{1} \cap F_{2} \cap F_{3} \cap F_{4} \cap F_{5}\right)$$

Les 5 lancés sont indépendants :

$$p=P\left(F_{1}\right) P\left(F_{2}\right) P\left(F_{3}\right) P\left(F_{4}\right) P\left(F_{5}\right) \\
p=\left(\frac{1}{2}\right)^{5}$$

# Variable aléatoire

##

Soit $\Omega$ l'ensemble fondamental des résultats d'une expérience aléatoire. L'attribution d'un nombre à chaque résultat de l'expérience permet de définir une variable aléatoire.

:::::: columns
::: {.column width="40%"}

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-35.jpg?height=341&width=480&top_left_y=388&top_left_x=80)

:::
::: {.column width="60%"}
- À chaque événement élémentaire $\omega$ correspond un nombre réel $x$.
- $x$ : réalisation de la variable $X$ pour l'événement $\omega$
- Attention, pas forcément autant de valeurs possibles $x$ que d'événements élémentaires $\omega$
:::
::::::

## 

### Exemple 1 : lancé d'un dé à 6 faces

- Expérience aléatoire : lancé d'un dé à 6 faces
- Univers des événements élémentaires possibles : $\{1 ; 2 ; 3 ; 4 ; 5 ; 6\}$
- Valeurs possibles pour la va : $\{1 ; 2 ; 3 ; 4 ; 5 ; 6\}$


### Exemple 2 : 

- Expérience aléatoire : détermination de l'infection d'une maladie sur des plantes
- Univers des possibles : \{positif; négatif\}
- Valeurs possibles pour la va : $\{0 ; 1\}$ (codage arbitraire)

##

### Définition

Une variable aléatoire sur $\Omega$ est une application $$X: \Omega \rightarrow \mathbb{R}$$ tel que $\forall(a, b) \in \mathbb{R} \quad X^{-1}([a, b])$ est un évènement

### Notations

- Les va sont notées avec des lettres majuscules : $X, Y, \ldots$
- Les valeurs possibles ou réalisations d'une va sont notées avec des lettres minuscules : $x_{i}, a, z, \ldots$

## 

### Deux types de variables aléatoires

**Une variable aléatoire est variable quantitative.**

- **Variable aléatoire discrète**

Elle prend un nombre fini ou infini dénombrable de valeurs possibles.

- **Variable aléatoire continue**

Elle prend un nombre infini indénombrable de valeurs possibles.


## Cas des variables aléatoires discrètes

### Définition

Soit $X$ une variable aléatoire discrète. Sa loi de probabilité est déterminée par

- I'ensemble des valeurs possibles $x_{i}(i \in I$, fini ou infini dénombrable)
- les probabilités $p_{i}=\mathrm{P}\left(X=x_{i}\right)$

### Propriétés

- $\forall i \in I$, $\ P\left(X=x_{i}\right) \geq 0$
- $\sum_{i \in I} \mathrm{P}\left(X=x_{i}\right)=\sum_{i \in I} p_{i}=1$

##

### Exemple de loi de probabilité discrète

- Hypothèse : Proba. d'avoir un veau mal pour une vache ($0.5$)

Distribution de probabilité ou loi de probabilité du nombre de femmelle dans un deux vélages consecutifs :

| événements possibles | MM | MF ou FM | FF |
| :--- | :---: | :---: | :---: |
| valeurs possibles | 0 | 1 | 2 |
| probabilités | $1 / 4$ | $1 / 2$ | $1 / 4$ |

- $\mathrm{P}(X=0)=\mathrm{P}(G \cap G)=\mathrm{P}(G) \times \mathrm{P}(G)$ (indépendance)
- $\mathrm{P}(X=1)=\mathrm{P}((G \cap F) \cup(F \cap G))=\mathrm{P}(G \cap F)+\mathrm{P}(F \cap G)$ (incompatibilité)

## Fonction de répartition : cas discret

### Définition

On appelle fonction de répartition de $X$ toute fonction $F$ telle que pour tout $t \in \mathbb{R}$, $$F(t)=\mathrm{P}(X \leq t)$$

### Interprétation

La fonction de répartition correspond à la distribution des probabilités cumulées

##

### Retour sur l'exemple

:::::: columns
::: {.column width="35%"}


| Valeurs possibles | Probabilités |
| :---: | :---: |
| 0 | 0,25 |
| 1 | 0,5 |
| 2 | 0,25 |

:::

::: {.column width="10%"}

:::


::: {.column width="55%"}

$$
\begin{array}{cl}
t<0 & \mathrm{P}(X \leq t)=0 \\
t=0 & \mathrm{P}(X \leq t)=0,25 \\
0<t<1 & \mathrm{P}(X \leq t)=0,25 \\
t=1 & \mathrm{P}(X \leq t)=0,75 \\
1<t<2 & \mathrm{P}(X \leq t)=0,75 \\
t=2 & \mathrm{P}(X \leq t)=1 \\
t>2 & \mathrm{P}(X \leq t)=1
\end{array}
$$

:::
::::::

##

On a alors :

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-42.jpg?height=331&width=510&top_left_y=578&top_left_x=80)
![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-42.jpg?height=332&width=516&top_left_y=578&top_left_x=646)

##

### Propriétés

- $\forall t \in \mathbb{R}$, \ \ $0 \leq F(t) \leq 1$
- F est croissante
- $\lim _{x \rightarrow-\infty} F(x)=0$
- $\lim _{x \rightarrow+\infty} F(x)=1$

Dans le cas discret, F est une fonction «en marches d'escalier»
Calcul de probabilités

$$
\begin{gathered}
\mathrm{P}\left(X=x_{i}\right)=\mathrm{P}\left(X \leq x_{i}\right)-\mathrm{P}\left(X \leq x_{i-1}\right) \\
\mathrm{P}\left(X=x_{i}\right)=F\left(x_{i}\right)-F\left(x_{i-1}\right)
\end{gathered}
$$

## Cas des variables aléatoires continues

### Problème

L'ensemble des valeurs possibles de $X$ est infini indénombrable

- On ne peut définir la loi de probabilité par l'ensemble des $\left(x_{i}, p_{i}\right)$
- En général, $\forall i, \mathrm{P}\left(X=x_{i}\right)=p_{i}=0$

##

### Densité de probabilité

On appelle densité de probabilité (ddp) toute fonction $f$ telle que :

- $\forall x \in \mathbb{R}, f(x) \geq 0$
- $\displaystyle\int_{-\infty}^{+\infty} f(x) d x=1$ (aire sous la courbe égale à 1 )

:::::: columns
::: {.column width="60%"}

### Probabilité d'un intervalle

$$
\mathrm{P}(a \leq X \leq b)=\int_{a}^{b} f(x) d x
$$

:::

::: {.column width="40%"}
![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-44.jpg?height=273&width=418&top_left_y=663&top_left_x=724)
:::

::::::

## Fonction de répartition : cas continu

**Même définition que dans le cas discret**

On appelle fonction de répartition de $X$ toute fonction $F$ telle que $\forall x \in \mathbb{R}, F(x)=\mathrm{P}(X \leq x)$

**Cas continu** : la fonction de répartition est continue et non plus en marches d'escalier !

:::::: columns
::: {.column width="40%"}

On a $$F(x)=\int_{-\infty}^{x} f(t) d t$$

:::
::: {.column width="60%"}
d'où

$$\mathrm{P}(a \leq X \leq b)=\int_{a}^{b} f(t) d t=F(b)-F(a)$$

:::
::::::

##

**Espérance = moyenne théorique**

Elle renseigne sur la position des valeurs possibles sur une échelle.

**Définition dans le cas d'une va discrète** :

$$\mathrm{E}(X)=\sum_{i} x_{i} \times P\left(X=x_{i}\right)=\sum_{i} x_{i} \times p_{i}$$

**Définition dans le cas d'une va continue**
$$
\mathrm{E}(X)=\int_{-\infty}^{+\infty} x f(x) d x
$$

##

### Propriété de l'espérance

**Linéarité**

Soient $X$ et $Y$ deux va et $a$ et $b$ des nombres réels :

$$
\begin{gathered}
\mathrm{E}(a X+b)=a \mathrm{E}(X)+b \\
\mathrm{E}(X+Y)=\mathrm{E}(X)+\mathrm{E}(Y)
\end{gathered}
$$

**Variable centrée**

- Si $\mathrm{E}(X)=0$ alors $X$ est une **va centrée**
- la va $Y=X-\mathrm{E}(X)$ est la va centrée associée à $X$


## Variance d'une va

### Rappel : variance d'une distribution

![](https://cdn.mathpix.com/cropped/2025_09_17_68f9d5d55601c91876fcg-48.jpg?height=257&width=498&top_left_y=173&top_left_x=115)

La variance d'une distribution mesure sa dispersion autour de sa moyenne

### Définition (cas discret ou continu)

Soit $X$ une va. 

La variance de $X$ se note $\operatorname{var}(X)$ ou $\sigma_{X}^{2}$ et est définie par :

$$
\sigma_X^2=\mathrm{E}\left((X-\mathrm{E}(X))^{2}\right)
$$

##

Autre formule équivalente, plus pratique pour les calculs

$$
\sigma_X^2=\mathrm{E}\left(X^{2}\right)-\mathrm{E}(X)^{2}
$$

### Propriétés d'une variance

- Une variance est toujours positive (ou nulle)
- La variance n'est pas linéaire !
- Si $\operatorname{var}(X)=1$ alors $X$ est une va réduite

:::::: columns
::: {.column width="50%"}

$$
\begin{gathered}
\operatorname{var}(a X)=a^{2} \operatorname{var}(X) \\
\operatorname{var}(X+b)=\operatorname{var}(X)
\end{gathered}
$$

:::
::: {.column width="50%"}
$$
\begin{gathered}
\operatorname{var}(a X+b)=a^{2} \operatorname{var}(X) \\
\operatorname{var}(X+Y)=\operatorname{var}(X)+\operatorname{var}(Y)
\\+2 \operatorname{cov}(X, Y)
\end{gathered}
$$
:::
::::::

## Écart-type d'une variable aléatoire

### Définition

Soit $X$ une va. L'écart-type de $X$ se note $\sigma_{X}$ et se définit par :

$$
\sigma_{X}=\sqrt{\operatorname{var}(X)}
$$

Intérêt : mesure de dispersion dans la même unité de mesure que $X$

##

### Variable centrée réduite

Soit $X$ une variable aléatoire d'espérance $\mathrm{E}(X)$ et d'écart-type $\sigma_{X}$

$$
Z=\frac{X-E(X)}{\sigma_{X}}
$$

$Z$ est la variable aléatoire centrée réduite associée à $X$

- $\displaystyle\mathrm{E}(Z)=\mathrm{E}\left(\frac{X-E(X)}{\sigma_{X}}\right)=\frac{1}{\sigma_{X}} \times(\mathrm{E}(X)-\mathrm{E}(X))=0$
- $\displaystyle\operatorname{var}(Z)=\sigma_{Z}^{2}=\frac{1}{\sigma_{X}^{2}} \times \operatorname{var}(X-\mathrm{E}(X))=1$


# Lois classiques

- Lois discrètes : Bernoulli et binomiale
- Lois continues : loi normale
